{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Linkedin Learning: Python Automation \n",
                "\n",
                "#### 1. [Automating Data Manipulation and Validation](#auto_data)\n",
                "#### 2. [Web Scrapping with BeautifulSoup](#web_scrap)\n",
                "#### 3. [Web Browsing with Selenium](#Selenium)\n",
                "#### 4. [API](#API)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Automating Data Manipulation and Validation\n",
                "<a id=\"auto_data\"></a>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Read File\n",
                "input_file = open(\"inputFile.txt\", \"r\")\n",
                "for line in input_file:\n",
                "    line_split = line.split()\n",
                "    if line_split[2] == \"P\":\n",
                "        print(line)\n",
                "input_file.close()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mary 25 P\n",
                        "\n",
                        "John 32 P\n",
                        "\n",
                        "Hailey 26 P\n",
                        "\n",
                        "Iris 23 P\n",
                        "\n",
                        "Jacob 29 P\n",
                        "\n",
                        "Jamie 26 P\n",
                        "\n",
                        "Chloe 21 P\n",
                        "\n",
                        "Natalie 29 P\n",
                        "\n",
                        "David 23 P\n",
                        "\n",
                        "Mario 51 P\n",
                        "\n",
                        "Josh 39 P\n",
                        "\n",
                        "Kayla 28 P\n",
                        "\n",
                        "Hunter 61 P\n",
                        "\n",
                        "Erica 16 P\n",
                        "\n",
                        "Kyle 19 P\n",
                        "\n",
                        "Rosanna 45 P\n",
                        "\n",
                        "Joy 28 P\n",
                        "\n",
                        "Jim 67 P\n",
                        "\n",
                        "Sansa 28 P\n",
                        "\n",
                        "Juan 73 P\n",
                        "\n",
                        "Colin 59 P\n",
                        "\n",
                        "Kate 58 P\n",
                        "\n",
                        "Jade 26 P\n",
                        "\n",
                        "River 29 P\n",
                        "\n",
                        "Chris 31 P\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# Write File\n",
                "\n",
                "# Read file for data extraction\n",
                "input_file = open(\"inputFile.txt\", \"r\")\n",
                "\n",
                "# Read file for entering data\n",
                "pass_file = open(\"passFile.txt\", \"w\")\n",
                "fail_file = open(\"failFile.txt\", \"w\")\n",
                "\n",
                "# Data extraction using for loop\n",
                "for line in input_file:\n",
                "    line_split = line.split()\n",
                "    if line_split[2] == \"P\":\n",
                "        pass_file.write(line)\n",
                "    else:\n",
                "        fail_file.write(line)\n",
                "\n",
                "# Close file\n",
                "input_file.close()\n",
                "pass_file.close()\n",
                "fail_file.close()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# Command line interface\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "for i in range(5):\n",
                "    subprocess.check_call([sys.executable, \"example.py\"])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# file organizer\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# define the categories and file types\n",
                "SUBDIRECTORIES = {\n",
                "    \"DOCUMENTS\": ['.pdf','.rtf','.txt'],\n",
                "    \"AUDIOS\": ['.m4a','.m4b','.mp3'],\n",
                "    \"VIDEOS\": ['.mov','.avi','.mp4'],\n",
                "    \"IMAGES\": ['.jpg','.jpeg','.png']\n",
                "}\n",
                "\n",
                "# define a function return the category based on the file types\n",
                "def pickDirectory(filetype):\n",
                "    for category, suffixes in SUBDIRECTORIES.items():\n",
                "        if filetype in suffixes:\n",
                "            return category\n",
                "        return \"MISC\"\n",
                "print(pickDirectory(\".pdf\"))\n",
                "\n",
                "# define a function to organize the file in the corresponding filetype\n",
                "def organizeDirectory():\n",
                "    for item in os.scandir():\n",
                "        if item.is_dir():\n",
                "            continue\n",
                "        filepath = Path(item)\n",
                "        filetype = filepath.suffix.lower()\n",
                "        directory = pickDirectory(filetype)\n",
                "        directorypath = Path(directory)\n",
                "        if directorypath.is_dir() != True:\n",
                "            directorypath.mkdir()\n",
                "        filepath.rename(directorypath.joinpath(filepath))\n",
                "\n",
                "organizeDirectory()\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "DOCUMENTS\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "# Parse data\n",
                "\n",
                "# text\n",
                "file_path = \"DOCUMENTS/groceries.txt\"\n",
                "\n",
                "with open(file_path, \"r\") as file:\n",
                "    data = file.read()\n",
                "\n",
                "# print(\"data:\", data)\n",
                "data_split = data.split()\n",
                "print(data_split)\n",
                "\n",
                "# CSV\n",
                "import csv\n",
                "\n",
                "filepath = \"MISC/groceries.csv\"\n",
                "\n",
                "with open(filepath, \"r\") as file:\n",
                "    csv_reader = csv.reader(file)\n",
                "    headers = next(csv_reader)\n",
                "    for row in csv_reader:\n",
                "        row[1] = int(row[1]) #make column 2 integer \n",
                "        print(row)\n",
                "\n",
                "# JSON\n",
                "import json\n",
                "\n",
                "file_path = \"MISC/groceries.json\"\n",
                "\n",
                "with open(file_path, \"r\") as file:\n",
                "    data = file.read()\n",
                "\n",
                "JSON_data = json.loads(data)\n",
                "print(\"ginger Q:\", JSON_data[\"ginger\"])\n",
                "\n",
                "# XML\n",
                "import xml.etree.ElementTree as ET\n",
                "\n",
                "filepath = \"MISC/groceries.xml\"\n",
                "\n",
                "tree = ET.parse(filepath)\n",
                "root = tree.getroot()\n",
                "\n",
                "for item in root.findall(\"grocery_item\"):\n",
                "    name = item.find(\"name\").text\n",
                "    price = item.find(\"price\").text\n",
                "    #print(name, price)\n",
                "\n",
                "# select item whose price is above 6\n",
                "item_above_six = []\n",
                "\n",
                "for item in root.findall(\"grocery_item\"):\n",
                "    name = item.find(\"name\").text\n",
                "    price = item.find(\"price\").text\n",
                "    if float(price) > 6.00:\n",
                "        item_above_six.append(name)\n",
                "    \n",
                "print(item_above_six)\n",
                "    "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['apples,', 'bananas,', 'carrots,', 'durians,', 'eggplants,', 'ginger,', 'hazelnuts']\n",
                        "['apples', 2]\n",
                        "['bananas', 6]\n",
                        "['carrots', 4]\n",
                        "['durians', 3]\n",
                        "['eggplants', 5]\n",
                        "['ginger', 1]\n",
                        "['hazelnuts', 8]\n",
                        "ginger Q: 1\n",
                        "['Avocados (per bag)', 'Coffee (per pound)', 'Almonds (per pound)', 'Avocado Oil', 'Truffle Oil', 'Saffron (per gram)']\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# Extract data with regular expression\n",
                "import re\n",
                "\n",
                "example = \"The number is 123-456-7890.\"\n",
                "\n",
                "phoneNumRegex = re.compile(r\"\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d\")\n",
                "result = phoneNumRegex.search(example)\n",
                "\n",
                "if result:\n",
                "    print(\"Phone found:\", result.group())\n",
                "    print(\"Area code:\", result.group()[0:3])\n",
                " "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Phone found: 123-456-7890\n",
                        "Area code: 123\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Install a package "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# Install package\n",
                "import sys\n",
                "!{sys.executable} -m pip install pyinputplus"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Collecting pyinputplus\n",
                        "  Using cached PyInputPlus-0.2.12-py3-none-any.whl\n",
                        "Collecting pysimplevalidate>=0.2.7 (from pyinputplus)\n",
                        "  Using cached PySimpleValidate-0.2.12-py3-none-any.whl\n",
                        "Collecting stdiomask>=0.0.3 (from pyinputplus)\n",
                        "  Using cached stdiomask-0.0.6-py3-none-any.whl\n",
                        "Installing collected packages: stdiomask, pysimplevalidate, pyinputplus\n",
                        "Successfully installed pyinputplus-0.2.12 pysimplevalidate-0.2.12 stdiomask-0.0.6\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
                        "[notice] To update, run: C:\\Users\\desti\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "# Input validation\n",
                "import pyinputplus as pyip\n",
                "\n",
                "print(\"\\nNumerical example\")\n",
                "# Numerical \n",
                "result = pyip.inputInt(\"Enter your lucky number from 0 to 10\", min = 0, max = 10)\n",
                "print(\"\\nYour lucky number is \", result)\n",
                "\n",
                "print(\"\\nMulti. Choice example\")\n",
                "# Letter only\n",
                "result = pyip.inputMenu([\"Ronaldo\", \"LBJ\", \"Elon\"], lettered=1, numbered=0)\n",
                "print(\"\\nYour fav athlete is \", result)\n",
                "\n",
                "print(\"\\nEmail example\")\n",
                "#Email \n",
                "result = pyip.inputEmail(\"Enter your email:\")\n",
                "print(\"\\nYour email is \", result)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Numerical example\n",
                        "Enter your lucky number from 0 to 10"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Your lucky number is  1\n",
                        "\n",
                        "Multi. Choice example\n",
                        "Please select one of the following:\n",
                        "A. Ronaldo\n",
                        "B. LBJ\n",
                        "C. Elon\n",
                        "'2' is not a valid choice.\n",
                        "Please select one of the following:\n",
                        "A. Ronaldo\n",
                        "B. LBJ\n",
                        "C. Elon\n",
                        "\n",
                        "Your fav athlete is  Ronaldo\n",
                        "\n",
                        "Email example\n",
                        "Enter your email:\n",
                        "Your email is  dsa@dd.cc\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "# Error handling\n",
                "\n",
                "# Check for computing error\n",
                "try:\n",
                "    num = int(input(\"Enter a number: \"))\n",
                "    result = int(10/num)\n",
                "    print(\"10 divided by the number you entered is \", result)\n",
                "except ValueError:\n",
                "    print(\"Plz enter a number\")\n",
                "except ZeroDivisionError:\n",
                "    print(\"Plz dun enter 0\")\n",
                "\n",
                "# Check for logical error (no error message but incorrect result)\n",
                "list = [1, 2, 3]\n",
                "list.reverse()\n",
                "print(list)\n",
                "try:\n",
                "    assert list[0] <= list[-1]\n",
                "except AssertionError:\n",
                "    print(\"error spotted\")\n",
                "    list.sort()\n",
                "assert list[0] <= list[-1]\n",
                "print(\"fine\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "10 divided by the number you entered is  10\n",
                        "[3, 2, 1]\n",
                        "error spotted\n",
                        "fine\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. Web Scrapping using Beautifulsoup\n",
                "<a id=\"web_scrap\"></a>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "# Install package\n",
                "import sys\n",
                "# !{sys.executable} -m pip install numpy"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "# Update package\n",
                "# import sys\n",
                "# !{sys.executable} -m pip uninstall numpy pandas -y\n",
                "# !{sys.executable} -m pip install numpy pandas"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "# Web scrapping - 1 \n",
                "# import from HTML\n",
                "\n",
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "import pandas\n",
                "\n",
                "url=\"https://maec.hkust.edu.hk/curriculum-structure-2024-25\"\n",
                "\n",
                "# Get the html data from the url\n",
                "response = requests.get(url, headers={\"Accept\": \"text/html\"})\n",
                "\n",
                "# Parse the text data using beautifulsoup\n",
                "parsed_response = BeautifulSoup(response.text, \"html.parser\")\n",
                "\n",
                "# format the html text\n",
                "formatted_response = parsed_response.prettify()\n",
                "\n",
                "# write the response to a HTML file\n",
                "with open(\"MAEC_Curriculum_scrapped.html\", \"w\", encoding=\"utf-8\") as file:\n",
                "    file.write(str(formatted_response))\n",
                "\n",
                "# print(parsed_response)\n",
                "\n",
                "# Parse the specificed text \n",
                "table_subject_area = parsed_response.find_all(\"tr\", class_=\"field_item\")\n",
                "\n",
                "# print(table_subject_area)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "import sys\n",
                "# !{sys.executable} -m pip install pandas"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "# Web scrapping-2\n",
                "# Scrap specific data\n",
                "\n",
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "import pandas as pd\n",
                "\n",
                "url = \"https://maec.hkust.edu.hk/curriculum-structure-2024-25\"\n",
                "\n",
                "# Scrap data from the web\n",
                "response = requests.get(url, headers={\"Accept\": \"text/html\"})\n",
                "parsed_response = BeautifulSoup(response.text, \"html.parser\")\n",
                "\n",
                "# search for the specific data\n",
                "MAEC_curriculum_div = parsed_response.find_all(\"div\", class_=\"field field--name-field-mod-long-fmt field--type-text-long field--label-visually_hidden mtpc-textarea mtpc-block-textare-block-textarea\")\n",
                "\n",
                "# list to store scrapped data\n",
                "data = []\n",
                "\n",
                "for div in MAEC_curriculum_div:\n",
                "    table = div.find(\"table\")\n",
                "    if table:\n",
                "        rows = table.find_all(\"tr\")[1:] #skip the header\n",
                "        for row in rows: \n",
                "            cols = row.find_all(\"td\")\n",
                "            if len(cols) >= 2:\n",
                "                subject_area = cols[0].text.strip()\n",
                "                no_of_coruses = cols[1].text.strip()\n",
                "                data.append([subject_area, no_of_coruses])\n",
                "        \n",
                "        # Convert data into dataframe, then HTML\n",
                "        df = pd.DataFrame(data, columns=[\"Subject Area\", \"No. of Courses\"])\n",
                "        df.to_html(\"MAEC_curriculum_subject_courses.html\", index=False)\n",
                "        break"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "# Web scrapping-3\n",
                "# Scrap through multi page\n",
                "\n",
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "import pandas as pd\n",
                "from time import sleep\n",
                "\n",
                "# for loop to iterate over the range of pages you want to scrape from\n",
                "list_of_curriculum = [\"\",\"0\",\"1\",\"2024-25\"]\n",
                "\n",
                "range = len(list_of_curriculum) - 1\n",
                "\n",
                "for academic_year in list_of_curriculum:\n",
                "    url = \"https://maec.hkust.edu.hk/curriculum-structure-\" + academic_year\n",
                "    \n",
                "    # Scrap data\n",
                "    response = requests.get(url, headers={\"Accept\": \"html/text\"})\n",
                "    parsed_response = BeautifulSoup(response.text, \"html.parser\")\n",
                "\n",
                "    #Search for the subject and number of courses from the text\n",
                "    MAEC_parsed_div = parsed_response.find_all(\"div\", class_=\"field field--name-field-mod-long-fmt field--type-text-long field--label-visually_hidden mtpc-textarea mtpc-block-textare-block-textarea\")\n",
                "    \n",
                "    # create an empty list to store data\n",
                "    data = []\n",
                "\n",
                "    for div in MAEC_curriculum_div:\n",
                "        table = div.find(\"table\")\n",
                "        if table:\n",
                "            rows = table.find_all(\"tr\")[1:] #remove the header\n",
                "            for row in rows:\n",
                "                cols = row.find_all(\"td\")\n",
                "                subject_area = cols[0].text.strip()\n",
                "                num_of_course = cols[1].text.strip()\n",
                "                data.append([subject_area, num_of_course])\n",
                "            df = pd.DataFrame(data, columns=[\"Subjects of Area\", \"No. of Courses\"])\n",
                "            file_name = \"MAEC_Curriculum_subject_courses-\" + academic_year + \".html\"\n",
                "            df.to_html(file_name, index=False)\n",
                "            break\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Auto Web Browsing with Selenium\n",
                "<a id=\"selenium\"></a>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# Install package\n",
                "import sys\n",
                "!{sys.executable} -m pip install webdriver_manager"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Collecting webdriver_manager\n",
                        "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
                        "Requirement already satisfied: requests in c:\\users\\desti\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from webdriver_manager) (2.31.0)\n",
                        "Collecting python-dotenv (from webdriver_manager)\n",
                        "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
                        "Requirement already satisfied: packaging in c:\\users\\desti\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from webdriver_manager) (23.2)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\desti\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->webdriver_manager) (3.3.1)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\desti\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->webdriver_manager) (3.4)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\desti\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->webdriver_manager) (1.26.15)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\desti\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->webdriver_manager) (2022.12.7)\n",
                        "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
                        "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
                        "Installing collected packages: python-dotenv, webdriver_manager\n",
                        "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.2\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
                        "[notice] To update, run: C:\\Users\\desti\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "# Basic browser interaction\n",
                "\n",
                "# import relevant libraries\n",
                "from selenium import webdriver\n",
                "from selenium.webdriver.chrome.service import Service as ChromeService\n",
                "from webdriver_manager.chrome import ChromeDriverManager\n",
                "from selenium.webdriver.common.by import By\n",
                "from time import sleep\n",
                "\n",
                "# Define URL\n",
                "url = \"https://ecommerce-playground.lambdatest.io/index.php?route=account/register\"\n",
                "\n",
                "# open a browser on chrome\n",
                "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
                "driver.maximize_window()\n",
                "driver.get(url)\n",
                "\n",
                "# enter the first name field\n",
                "first_name = driver.find_element(By.XPATH, '//*[@id=\"input-firstname\"]')\n",
                "first_name.send_keys(\"Email\") #fill out data\n",
                "\n",
                "# enter the last name field\n",
                "last_name = driver.find_element(By.XPATH, '//*[@id=\"input-lastname\"]')\n",
                "last_name.send_keys(\"Kam\") #fill out data\n",
                "\n",
                "# enter the email field\n",
                "email = driver.find_element(By.XPATH, '//*[@id=\"input-email\"]')\n",
                "email.send_keys(\"kam@email.on.dog\") #fill out data\n",
                "\n",
                "# enter the telephone field\n",
                "first_name = driver.find_element(By.XPATH, '//*[@id=\"input-telephone\"]')\n",
                "first_name.send_keys(\"Email\") #fill out data\n",
                "\n",
                "# enter the password field\n",
                "password = driver.find_element(By.XPATH, '//*[@id=\"input-password\"]')\n",
                "password.send_keys(\"1234\") #fill out data\n",
                "\n",
                "# enter the password confirmed field\n",
                "password_confirm = driver.find_element(By.XPATH, '//*[@id=\"input-confirm\"]')\n",
                "password_confirm.send_keys(\"1234\") #fill out data\n",
                "\n",
                "# click to the newsletter subscribe button\n",
                "newsletter_subscribe = driver.find_element(By.XPATH, '//*[@id=\"content\"]/form/fieldset[3]/div/div/div[2]/label')\n",
                "newsletter_subscribe.click() #fill out data\n",
                "\n",
                "# click agree button\n",
                "agree = driver.find_element(By.XPATH, '//*[@id=\"content\"]/form/div/div/div/label')\n",
                "agree.click() #fill out data\n",
                "\n",
                "# click continue button\n",
                "continue_button = driver.find_element(By.XPATH, '//*[@id=\"content\"]/form/div/div/input')\n",
                "continue_button.click() #fill out data\n",
                "\n",
                "#scroll down by 200 units to view the lower part of the page\n",
                "driver.execute_script(\"window.scrollTo(0, window.scrollY + 200)\")\n",
                "\n",
                "# pause for 5 sec to view the result\n",
                "sleep(5)\n",
                "\n",
                "# close the drver\n",
                "driver.quit()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "# drag and drop\n",
                "\n",
                "from selenium import webdriver\n",
                "from selenium.webdriver.chrome.service import Service as ChromeService\n",
                "from webdriver_manager.chrome import ChromeDriverManager\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.common.action_chains import ActionChains\n",
                "from time import sleep\n",
                "\n",
                "# Define URL\n",
                "url = \"http://dhtmlgoodies.com/scripts/drag-drop-custom/demo-drag-drop-3.html\"\n",
                "\n",
                "# open a browser on chrome\n",
                "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
                "driver.maximize_window()\n",
                "driver.get(url)\n",
                "\n",
                "# find the source for drag\n",
                "source = driver.find_element(By.XPATH, '//*[@id=\"box3\"]')\n",
                "\n",
                "# find the destination for drag\n",
                "destination = driver.find_element(By.XPATH, '//*[@id=\"box103\"]')\n",
                "\n",
                "# perform the drag and drop\n",
                "actions = ActionChains(driver)\n",
                "actions.drag_and_drop(source, destination).perform()\n",
                "\n",
                "# pause for 5 sec to run\n",
                "sleep(5)\n",
                "\n",
                "# close the drver\n",
                "driver.quit()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "# Explicit wait\n",
                "\n",
                "from selenium import webdriver\n",
                "from selenium.webdriver.chrome.service import Service as ChromeService\n",
                "from webdriver_manager.chrome import ChromeDriverManager\n",
                "from selenium.webdriver.common.by import By\n",
                "from selenium.webdriver.support.ui import WebDriverWait\n",
                "from selenium.webdriver.support import expected_conditions as EC\n",
                "from time import sleep\n",
                "\n",
                "# Define URL\n",
                "url = \"https://the-internet.herokuapp.com/dynamic_controls\"\n",
                "\n",
                "# open a browser on chrome\n",
                "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
                "driver.maximize_window()\n",
                "driver.get(url)\n",
                "\n",
                "# define a wait\n",
                "wait = WebDriverWait(driver, 10)\n",
                "\n",
                "# find the Enable button and click\n",
                "enable_button = driver.find_element(By.XPATH, '//*[@id=\"input-example\"]/button')\n",
                "enable_button.click()\n",
                "sleep(3)\n",
                "\n",
                "# disable the button after load time\n",
                "disable_button = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"input-example\"]/button')))\n",
                "disable_button.click()\n",
                "sleep(3)\n",
                "\n",
                "# find the remove button and click\n",
                "remove_button = driver.find_element(By.XPATH, '//*[@id=\"checkbox-example\"]/button')\n",
                "remove_button.click()\n",
                "sleep(3)\n",
                "\n",
                "# find the add button and click\n",
                "add_button = driver.find_element(By.XPATH, '//*[@id=\"checkbox-example\"]/button')\n",
                "add_button.click()\n",
                "sleep(3)\n",
                "\n",
                "# click the checkbox after the load time \n",
                "checkbox = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"checkbox\"]')))\n",
                "checkbox.click()\n",
                "sleep(3)\n",
                "\n",
                "# close the drver\n",
                "driver.quit()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. API\n",
                "<a id=\"API\"></a>\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "# API request\n",
                "import requests\n",
                "\n",
                "# Define URL\n",
                "url = \"https://api.upcitemdb.com/prod/trial/lookup\"\n",
                "\n",
                "# define parameters\n",
                "parameters = {\"upc\": \"025000044908\"}\n",
                "\n",
                "# make API request, passing in base URL and parameters\n",
                "response = requests.get(url, params=parameters)\n",
                "\n",
                "# print out the response URL\n",
                "print(response.url)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "https://api.upcitemdb.com/prod/trial/lookup?upc=025000044908\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# Parse API response in Python with JSON\n",
                "# API request\n",
                "import requests\n",
                "import json\n",
                "\n",
                "# Example 1: lemonade with raspberry\n",
                "print(\"\\nProduct example 1\\n\")\n",
                "# Define URL\n",
                "url = \"https://api.upcitemdb.com/prod/trial/lookup\"\n",
                "\n",
                "# define parameters\n",
                "parameters = {\"upc\": \"025000044908\"}\n",
                "\n",
                "# make API request, passing in base URL and parameters\n",
                "response = requests.get(url, params=parameters)\n",
                "\n",
                "# parse the text from the API repsonse using JSON schema\n",
                "info = json.loads(response.text)\n",
                "\n",
                "#print the title and brand of the product\n",
                "item = info[\"items\"][0]\n",
                "title = item[\"title\"]\n",
                "brand = item[\"brand\"]\n",
                "print(\"title:\", title)\n",
                "print(\"brand:\", brand)\n",
                "\n",
                "# Example 2: lemonade with raspberry\n",
                "print(\"\\nProduct example 2\\n\")\n",
                "# Define URL\n",
                "url = \"https://api.upcitemdb.com/prod/trial/lookup\"\n",
                "\n",
                "# define parameters\n",
                "parameters = {\"upc\": \"028400516686\"}\n",
                "\n",
                "# make API request, passing in base URL and parameters\n",
                "response = requests.get(url, params=parameters)\n",
                "\n",
                "# parse the text from the API repsonse using JSON schema\n",
                "info = json.loads(response.text)\n",
                "\n",
                "#print the title and brand of the product\n",
                "item = info[\"items\"][0]\n",
                "title = item[\"title\"]\n",
                "brand = item[\"brand\"]\n",
                "print(\"title:\", title)\n",
                "print(\"brand:\", brand)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Product example 1\n",
                        "\n",
                        "title: Simply Lemonade w/ Raspberry Bottle, 52 fl oz\n",
                        "brand: SIMPLY\n",
                        "\n",
                        "Product example 2\n",
                        "\n",
                        "title: Ruffles Potato Chips Original Snack Chips  8.5 Ounce Bag\n",
                        "brand: Ruffles\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "# Use API key \n",
                "import requests\n",
                "\n",
                "# Define URL\n",
                "url = \"http://api.openweathermap.org/data/2.5/forecast\"\n",
                "\n",
                "# define parameters\n",
                "parameters = {\"q\":\"Hong Kong,HK\", \"appid\":\"1bf20ea9960dc27c6711a92a66bc51e4\"}\n",
                "\n",
                "# make API request, passing in base URL and parameters\n",
                "response = requests.get(url, params=parameters)\n",
                "\n",
                "# print out the response URL\n",
                "print(response.text)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{\"cod\":\"200\",\"message\":0,\"cnt\":40,\"list\":[{\"dt\":1739620800,\"main\":{\"temp\":294.25,\"feels_like\":294.5,\"temp_min\":292.02,\"temp_max\":294.25,\"pressure\":1014,\"sea_level\":1014,\"grnd_level\":1009,\"humidity\":80,\"temp_kf\":2.23},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01n\"}],\"clouds\":{\"all\":1},\"wind\":{\"speed\":2.06,\"deg\":166,\"gust\":2.1},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-15 12:00:00\"},{\"dt\":1739631600,\"main\":{\"temp\":293.07,\"feels_like\":293.34,\"temp_min\":291.92,\"temp_max\":293.07,\"pressure\":1015,\"sea_level\":1015,\"grnd_level\":1011,\"humidity\":85,\"temp_kf\":1.15},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01n\"}],\"clouds\":{\"all\":2},\"wind\":{\"speed\":0.49,\"deg\":208,\"gust\":0.7},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-15 15:00:00\"},{\"dt\":1739642400,\"main\":{\"temp\":291.76,\"feels_like\":291.97,\"temp_min\":291.76,\"temp_max\":291.76,\"pressure\":1016,\"sea_level\":1016,\"grnd_level\":1010,\"humidity\":88,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"clouds\":{\"all\":13},\"wind\":{\"speed\":0.54,\"deg\":231,\"gust\":0.6},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-15 18:00:00\"},{\"dt\":1739653200,\"main\":{\"temp\":291.85,\"feels_like\":292.05,\"temp_min\":291.85,\"temp_max\":291.85,\"pressure\":1015,\"sea_level\":1015,\"grnd_level\":1010,\"humidity\":87,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01n\"}],\"clouds\":{\"all\":7},\"wind\":{\"speed\":1.17,\"deg\":353,\"gust\":1.17},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-15 21:00:00\"},{\"dt\":1739664000,\"main\":{\"temp\":292.44,\"feels_like\":292.59,\"temp_min\":292.44,\"temp_max\":292.44,\"pressure\":1017,\"sea_level\":1017,\"grnd_level\":1011,\"humidity\":83,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01d\"}],\"clouds\":{\"all\":7},\"wind\":{\"speed\":1.71,\"deg\":21,\"gust\":1.87},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-16 00:00:00\"},{\"dt\":1739674800,\"main\":{\"temp\":295.09,\"feels_like\":295.22,\"temp_min\":295.09,\"temp_max\":295.09,\"pressure\":1018,\"sea_level\":1018,\"grnd_level\":1013,\"humidity\":72,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02d\"}],\"clouds\":{\"all\":21},\"wind\":{\"speed\":1.29,\"deg\":298,\"gust\":1.62},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-16 03:00:00\"},{\"dt\":1739685600,\"main\":{\"temp\":294.92,\"feels_like\":295.06,\"temp_min\":294.92,\"temp_max\":294.92,\"pressure\":1016,\"sea_level\":1016,\"grnd_level\":1011,\"humidity\":73,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02d\"}],\"clouds\":{\"all\":18},\"wind\":{\"speed\":1.56,\"deg\":164,\"gust\":1.23},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-16 06:00:00\"},{\"dt\":1739696400,\"main\":{\"temp\":294,\"feels_like\":294.26,\"temp_min\":294,\"temp_max\":294,\"pressure\":1015,\"sea_level\":1015,\"grnd_level\":1010,\"humidity\":81,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01d\"}],\"clouds\":{\"all\":2},\"wind\":{\"speed\":4.75,\"deg\":118,\"gust\":4.79},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-16 09:00:00\"},{\"dt\":1739707200,\"main\":{\"temp\":292.41,\"feels_like\":292.69,\"temp_min\":292.41,\"temp_max\":292.41,\"pressure\":1017,\"sea_level\":1017,\"grnd_level\":1012,\"humidity\":88,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01n\"}],\"clouds\":{\"all\":2},\"wind\":{\"speed\":5.24,\"deg\":93,\"gust\":6.79},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-16 12:00:00\"},{\"dt\":1739718000,\"main\":{\"temp\":292.15,\"feels_like\":292.4,\"temp_min\":292.15,\"temp_max\":292.15,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1014,\"humidity\":88,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"clouds\":{\"all\":18},\"wind\":{\"speed\":6.37,\"deg\":81,\"gust\":8.34},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-16 15:00:00\"},{\"dt\":1739728800,\"main\":{\"temp\":291.57,\"feels_like\":291.74,\"temp_min\":291.57,\"temp_max\":291.57,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1013,\"humidity\":87,\"temp_kf\":0},\"weather\":[{\"id\":802,\"main\":\"Clouds\",\"description\":\"scattered clouds\",\"icon\":\"03n\"}],\"clouds\":{\"all\":37},\"wind\":{\"speed\":7.34,\"deg\":77,\"gust\":10.09},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-16 18:00:00\"},{\"dt\":1739739600,\"main\":{\"temp\":290.96,\"feels_like\":290.99,\"temp_min\":290.96,\"temp_max\":290.96,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1013,\"humidity\":84,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":80},\"wind\":{\"speed\":9.6,\"deg\":78,\"gust\":12.47},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-16 21:00:00\"},{\"dt\":1739750400,\"main\":{\"temp\":291.16,\"feels_like\":291.11,\"temp_min\":291.16,\"temp_max\":291.16,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1015,\"humidity\":80,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":80},\"wind\":{\"speed\":10.12,\"deg\":81,\"gust\":13.08},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-17 00:00:00\"},{\"dt\":1739761200,\"main\":{\"temp\":292.28,\"feels_like\":292.15,\"temp_min\":292.28,\"temp_max\":292.28,\"pressure\":1022,\"sea_level\":1022,\"grnd_level\":1016,\"humidity\":73,\"temp_kf\":0},\"weather\":[{\"id\":802,\"main\":\"Clouds\",\"description\":\"scattered clouds\",\"icon\":\"03d\"}],\"clouds\":{\"all\":39},\"wind\":{\"speed\":9.55,\"deg\":86,\"gust\":12.12},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-17 03:00:00\"},{\"dt\":1739772000,\"main\":{\"temp\":292.51,\"feels_like\":292.28,\"temp_min\":292.51,\"temp_max\":292.51,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1014,\"humidity\":68,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02d\"}],\"clouds\":{\"all\":20},\"wind\":{\"speed\":9.03,\"deg\":89,\"gust\":10.98},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-17 06:00:00\"},{\"dt\":1739782800,\"main\":{\"temp\":291.77,\"feels_like\":291.59,\"temp_min\":291.77,\"temp_max\":291.77,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1014,\"humidity\":73,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01d\"}],\"clouds\":{\"all\":1},\"wind\":{\"speed\":8.27,\"deg\":85,\"gust\":9.75},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-17 09:00:00\"},{\"dt\":1739793600,\"main\":{\"temp\":290.94,\"feels_like\":290.73,\"temp_min\":290.94,\"temp_max\":290.94,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1016,\"humidity\":75,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01n\"}],\"clouds\":{\"all\":8},\"wind\":{\"speed\":8.41,\"deg\":85,\"gust\":10.5},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-17 12:00:00\"},{\"dt\":1739804400,\"main\":{\"temp\":290.62,\"feels_like\":290.41,\"temp_min\":290.62,\"temp_max\":290.62,\"pressure\":1022,\"sea_level\":1022,\"grnd_level\":1017,\"humidity\":76,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"clouds\":{\"all\":22},\"wind\":{\"speed\":9.12,\"deg\":83,\"gust\":11},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-17 15:00:00\"},{\"dt\":1739815200,\"main\":{\"temp\":290.19,\"feels_like\":289.93,\"temp_min\":290.19,\"temp_max\":290.19,\"pressure\":1022,\"sea_level\":1022,\"grnd_level\":1016,\"humidity\":76,\"temp_kf\":0},\"weather\":[{\"id\":802,\"main\":\"Clouds\",\"description\":\"scattered clouds\",\"icon\":\"03n\"}],\"clouds\":{\"all\":44},\"wind\":{\"speed\":9.88,\"deg\":80,\"gust\":11.71},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-17 18:00:00\"},{\"dt\":1739826000,\"main\":{\"temp\":289.59,\"feels_like\":289.3,\"temp_min\":289.59,\"temp_max\":289.59,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1016,\"humidity\":77,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":84},\"wind\":{\"speed\":10.13,\"deg\":79,\"gust\":12.15},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-17 21:00:00\"},{\"dt\":1739836800,\"main\":{\"temp\":289.51,\"feels_like\":289.16,\"temp_min\":289.51,\"temp_max\":289.51,\"pressure\":1023,\"sea_level\":1023,\"grnd_level\":1017,\"humidity\":75,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":83},\"wind\":{\"speed\":9.6,\"deg\":78,\"gust\":11.21},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-18 00:00:00\"},{\"dt\":1739847600,\"main\":{\"temp\":290.13,\"feels_like\":289.79,\"temp_min\":290.13,\"temp_max\":290.13,\"pressure\":1023,\"sea_level\":1023,\"grnd_level\":1018,\"humidity\":73,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":82},\"wind\":{\"speed\":8.63,\"deg\":78,\"gust\":9.34},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-18 03:00:00\"},{\"dt\":1739858400,\"main\":{\"temp\":291.01,\"feels_like\":290.68,\"temp_min\":291.01,\"temp_max\":291.01,\"pressure\":1020,\"sea_level\":1020,\"grnd_level\":1015,\"humidity\":70,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":65},\"wind\":{\"speed\":7.15,\"deg\":87,\"gust\":7.16},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-18 06:00:00\"},{\"dt\":1739869200,\"main\":{\"temp\":290.61,\"feels_like\":290.34,\"temp_min\":290.61,\"temp_max\":290.61,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1014,\"humidity\":74,\"temp_kf\":0},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02d\"}],\"clouds\":{\"all\":19},\"wind\":{\"speed\":7.54,\"deg\":93,\"gust\":7.78},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-18 09:00:00\"},{\"dt\":1739880000,\"main\":{\"temp\":290.3,\"feels_like\":290.11,\"temp_min\":290.3,\"temp_max\":290.3,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1016,\"humidity\":78,\"temp_kf\":0},\"weather\":[{\"id\":802,\"main\":\"Clouds\",\"description\":\"scattered clouds\",\"icon\":\"03n\"}],\"clouds\":{\"all\":27},\"wind\":{\"speed\":8.44,\"deg\":88,\"gust\":9.4},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-18 12:00:00\"},{\"dt\":1739890800,\"main\":{\"temp\":290.23,\"feels_like\":290.11,\"temp_min\":290.23,\"temp_max\":290.23,\"pressure\":1022,\"sea_level\":1022,\"grnd_level\":1016,\"humidity\":81,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":86},\"wind\":{\"speed\":9.05,\"deg\":87,\"gust\":10.85},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-18 15:00:00\"},{\"dt\":1739901600,\"main\":{\"temp\":289.78,\"feels_like\":289.64,\"temp_min\":289.78,\"temp_max\":289.78,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1016,\"humidity\":82,\"temp_kf\":0},\"weather\":[{\"id\":500,\"main\":\"Rain\",\"description\":\"light rain\",\"icon\":\"10n\"}],\"clouds\":{\"all\":91},\"wind\":{\"speed\":10.39,\"deg\":85,\"gust\":12.25},\"visibility\":10000,\"pop\":0.2,\"rain\":{\"3h\":0.17},\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-18 18:00:00\"},{\"dt\":1739912400,\"main\":{\"temp\":289.37,\"feels_like\":289.19,\"temp_min\":289.37,\"temp_max\":289.37,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1015,\"humidity\":82,\"temp_kf\":0},\"weather\":[{\"id\":500,\"main\":\"Rain\",\"description\":\"light rain\",\"icon\":\"10n\"}],\"clouds\":{\"all\":99},\"wind\":{\"speed\":11.04,\"deg\":82,\"gust\":12.63},\"visibility\":10000,\"pop\":0.26,\"rain\":{\"3h\":0.16},\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-18 21:00:00\"},{\"dt\":1739923200,\"main\":{\"temp\":289.46,\"feels_like\":289.26,\"temp_min\":289.46,\"temp_max\":289.46,\"pressure\":1022,\"sea_level\":1022,\"grnd_level\":1017,\"humidity\":81,\"temp_kf\":0},\"weather\":[{\"id\":500,\"main\":\"Rain\",\"description\":\"light rain\",\"icon\":\"10d\"}],\"clouds\":{\"all\":99},\"wind\":{\"speed\":10.53,\"deg\":85,\"gust\":12.56},\"visibility\":10000,\"pop\":0.29,\"rain\":{\"3h\":0.25},\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-19 00:00:00\"},{\"dt\":1739934000,\"main\":{\"temp\":289.93,\"feels_like\":289.75,\"temp_min\":289.93,\"temp_max\":289.93,\"pressure\":1023,\"sea_level\":1023,\"grnd_level\":1017,\"humidity\":80,\"temp_kf\":0},\"weather\":[{\"id\":500,\"main\":\"Rain\",\"description\":\"light rain\",\"icon\":\"10d\"}],\"clouds\":{\"all\":100},\"wind\":{\"speed\":10.1,\"deg\":78,\"gust\":11.77},\"visibility\":10000,\"pop\":0.2,\"rain\":{\"3h\":0.14},\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-19 03:00:00\"},{\"dt\":1739944800,\"main\":{\"temp\":290.33,\"feels_like\":290.11,\"temp_min\":290.33,\"temp_max\":290.33,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1014,\"humidity\":77,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":97},\"wind\":{\"speed\":8.98,\"deg\":79,\"gust\":9.76},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-19 06:00:00\"},{\"dt\":1739955600,\"main\":{\"temp\":290.41,\"feels_like\":290.25,\"temp_min\":290.41,\"temp_max\":290.41,\"pressure\":1018,\"sea_level\":1018,\"grnd_level\":1013,\"humidity\":79,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":85},\"wind\":{\"speed\":7.09,\"deg\":78,\"gust\":8.06},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-19 09:00:00\"},{\"dt\":1739966400,\"main\":{\"temp\":290.3,\"feels_like\":290.24,\"temp_min\":290.3,\"temp_max\":290.3,\"pressure\":1020,\"sea_level\":1020,\"grnd_level\":1014,\"humidity\":83,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":86},\"wind\":{\"speed\":6.28,\"deg\":75,\"gust\":7.72},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-19 12:00:00\"},{\"dt\":1739977200,\"main\":{\"temp\":290.69,\"feels_like\":290.75,\"temp_min\":290.69,\"temp_max\":290.69,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1015,\"humidity\":86,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":100},\"wind\":{\"speed\":7.38,\"deg\":73,\"gust\":8.86},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-19 15:00:00\"},{\"dt\":1739988000,\"main\":{\"temp\":290.26,\"feels_like\":290.3,\"temp_min\":290.26,\"temp_max\":290.26,\"pressure\":1020,\"sea_level\":1020,\"grnd_level\":1015,\"humidity\":87,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":100},\"wind\":{\"speed\":7.29,\"deg\":73,\"gust\":8.92},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-19 18:00:00\"},{\"dt\":1739998800,\"main\":{\"temp\":290.01,\"feels_like\":290,\"temp_min\":290.01,\"temp_max\":290.01,\"pressure\":1019,\"sea_level\":1019,\"grnd_level\":1014,\"humidity\":86,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04n\"}],\"clouds\":{\"all\":100},\"wind\":{\"speed\":6.68,\"deg\":77,\"gust\":8.47},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"n\"},\"dt_txt\":\"2025-02-19 21:00:00\"},{\"dt\":1740009600,\"main\":{\"temp\":290.39,\"feels_like\":290.34,\"temp_min\":290.39,\"temp_max\":290.39,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1015,\"humidity\":83,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":100},\"wind\":{\"speed\":6.75,\"deg\":75,\"gust\":8.68},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-20 00:00:00\"},{\"dt\":1740020400,\"main\":{\"temp\":291.52,\"feels_like\":291.48,\"temp_min\":291.52,\"temp_max\":291.52,\"pressure\":1021,\"sea_level\":1021,\"grnd_level\":1016,\"humidity\":79,\"temp_kf\":0},\"weather\":[{\"id\":804,\"main\":\"Clouds\",\"description\":\"overcast clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":99},\"wind\":{\"speed\":6.59,\"deg\":81,\"gust\":7.93},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-20 03:00:00\"},{\"dt\":1740031200,\"main\":{\"temp\":292.39,\"feels_like\":292.35,\"temp_min\":292.39,\"temp_max\":292.39,\"pressure\":1018,\"sea_level\":1018,\"grnd_level\":1013,\"humidity\":76,\"temp_kf\":0},\"weather\":[{\"id\":803,\"main\":\"Clouds\",\"description\":\"broken clouds\",\"icon\":\"04d\"}],\"clouds\":{\"all\":62},\"wind\":{\"speed\":6.53,\"deg\":89,\"gust\":7.22},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-20 06:00:00\"},{\"dt\":1740042000,\"main\":{\"temp\":292.09,\"feels_like\":292.1,\"temp_min\":292.09,\"temp_max\":292.09,\"pressure\":1017,\"sea_level\":1017,\"grnd_level\":1012,\"humidity\":79,\"temp_kf\":0},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01d\"}],\"clouds\":{\"all\":9},\"wind\":{\"speed\":6.38,\"deg\":91,\"gust\":7.44},\"visibility\":10000,\"pop\":0,\"sys\":{\"pod\":\"d\"},\"dt_txt\":\"2025-02-20 09:00:00\"}],\"city\":{\"id\":1819729,\"name\":\"Hong Kong\",\"coord\":{\"lat\":22.2855,\"lon\":114.1577},\"country\":\"HK\",\"population\":7012738,\"timezone\":28800,\"sunrise\":1739573711,\"sunset\":1739614806}}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Connect API\n",
                "import requests\n",
                "\n",
                "# Define URL\n",
                "url = \"http://api.openweathermap.org/data/2.5/forecast\"\n",
                "\n",
                "# define parameters\n",
                "parameters = {\"q\":\"Hong Kong,HK\", \"appid\":\"1bf20ea9960dc27c6711a92a66bc51e4\"}\n",
                "\n",
                "# make API request, passing in base URL and parameters\n",
                "response = requests.get(url, params=parameters)\n",
                "\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.11.4 64-bit ('desti': virtualenv)"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "interpreter": {
            "hash": "14f685b93344d9be8bc3105cb11784fe9cb5aea4889a7cdc7d425e57f8a0455b"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}